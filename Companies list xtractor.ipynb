{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptation of the script made to fetch swiss companies to fetch other countries as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this purpose, we fetch the page using requests, and then parse its content using BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_companies(coutry):\n",
    "    r = requests.get('https://en.wikipedia.org/wiki/List_of_companies_of_' + country)\n",
    "    if r.status_code != 200:\n",
    "        print('HTTP ERROR ' + r.status_code + ' country: ' + country)\n",
    "        return []\n",
    "    \n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    content = soup.find_all(id = 'mw-content-text')\n",
    "    if len(content) < 1:\n",
    "        print(\"No companies found in \" + country)\n",
    "        return []\n",
    "\n",
    "    companies = []\n",
    "    for x in content[0].find_all('h2'):\n",
    "        nxt = x.find_next_sibling('ul')\n",
    "        if nxt == None:\n",
    "            continue\n",
    "            \n",
    "        for y in nxt.find_all('a'):\n",
    "            companies.append(y.string)\n",
    "\n",
    "    print(str(len(companies)) + ' companies found in ' + country)\n",
    "    return companies\n",
    "\n",
    "def to_csv(country, companies):\n",
    "    with open('companies/' + country + '_companies.csv', 'w') as f:\n",
    "        wr = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_french_companies():\n",
    "    r = requests.get('https://en.wikipedia.org/wiki/List_of_companies_of_France')\n",
    "    if r.status_code != 200:\n",
    "        print('HTTP ERROR ' + r.status_code + ' country: ' + country)\n",
    "        return []\n",
    "    \n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    content = soup.find_all(id = 'mw-content-text')\n",
    "    if len(content) < 1:\n",
    "        print(\"No companies found in \" + country)\n",
    "        return []\n",
    "\n",
    "    companies = []\n",
    "    for x in content[0].find_all('h2'):\n",
    "        nxt = x.find_next_sibling('div')\n",
    "        if nxt == None:\n",
    "            continue\n",
    "            \n",
    "        nxt = nxt.find('table', class_='multicol')\n",
    "        if nxt == None:\n",
    "            continue\n",
    "            \n",
    "        for y in nxt.find_all('a'):\n",
    "            companies.append(y.string)\n",
    "\n",
    "    print(str(len(companies)) + ' french companies found')\n",
    "    return companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_uk_companies():\n",
    "    r = requests.get('https://en.wikipedia.org/wiki/List_of_largest_private_companies_in_the_United_Kingdom')\n",
    "    if r.status_code != 200:\n",
    "        print('HTTP ERROR ' + r.status_code + ' country: ' + country)\n",
    "        return []\n",
    "    \n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    content = soup.find(id = 'mw-content-text').find('table', class_ = 'wikitable')\n",
    "\n",
    "    companies = []\n",
    "    for tr in content.find_all(lambda el: el.name == 'tr' and el.td != None):\n",
    "        try:\n",
    "            companies.append(tr.td.a.string)\n",
    "        except AttributeError:\n",
    "            companies.append(tr.td.string)\n",
    "\n",
    "    print(str(len(companies)) + ' companies found in the uk')\n",
    "    return companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countries = ['Germany',\n",
    "            'Italy',\n",
    "            'Spain'] #UK and France have special treatment because their wikipedia pages are not formatted the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347 companies found in Germany\n",
      "586 companies found in Italy\n",
      "151 companies found in Spain\n"
     ]
    }
   ],
   "source": [
    "for country in countries:\n",
    "    companies = get_companies(country)\n",
    "    to_csv(country, companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212 french companies found\n"
     ]
    }
   ],
   "source": [
    "to_csv(\"France\", get_french_companies())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 companies found in the uk\n"
     ]
    }
   ],
   "source": [
    "to_csv(\"UK\", get_uk_companies())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
